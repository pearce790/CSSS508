---
title: "CSSS 508, Lecture 3"
subtitle: "Manipulating and Summarizing Data"
author: "Michael Pearce<br>(based on slides from Chuck Lanfear)"
date: "October 13, 2022"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["center","top"]
---

```{r setup, include=FALSE,purl=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "##")
# setwd("/Users/pearce790/CSSS508/Lectures/Lecture3/")
# knitr::purl("CSSS508_Lecture3_dplyr.Rmd")
```

# A Quick Note

The last two lectures have been jam-packed with content! This makes it hard to answer individual-level questions as we get started with R and RStudio.

--

Luckily, today's lecture has **less content** and **more time for questions!** To keep things moving along,

+ Please try to **limit very-individual questions while I'm running through slides** (e.g., "I'm getting this error message, why is that?"). I'm happy to answer these while we're working on exercises, during a break/lab/office hour, or before/after class.

+ Please **interrupt me with questions about content during lecture!** If something isn't clear on the slides, it's best to discuss it right away!

---
class: inverse

# Topics

Last time, we learned about,

1. Useful coding tips: packages, directories, and saving data
1. Advanced data manipulation tools
1. Basics of ggplot: layers and aesthetics
1. Advanced ggplot tools

--

Today, we will cover,

1. Subsetting data
1. Modifying data 
1. Summarizing data
1. Joining (merging) data

---
class: inverse

# Death to Spreadsheets

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

You may be familiar with tools like Excel or Google Sheets, which let you manipulate data in a spreadsheet using functions. Spreadsheets are *not reproducible*: It's hard to know how someone changed the raw data!

Today we'll talk more about `dplyr`: an R package that does just about anything Excel can, but more *transparently*, *reproducibly*, and *safely*. 

Don't be the next sad research assistant who makes headlines with an Excel error ([Reinhart & Rogoff, 2010](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history))

---
class: inverse

# Subsetting data

+ `filter()`
+ `distinct()`
+ `select()`
+ `pull()`


---
# Reminder: Pipes (%>%)

In `dplyr`, we use the **pipe** operator (`%>%`) to make code readable. A keyboard shortcut to create pipes is `Ctrl+Shift+M` (Windows) or `Command+Shift+M` (OS).

--

Pipes take the object on the *left* and apply to it the function on the *right*:

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(gapminder)
gapminder %>% filter(country == "Canada") %>% head(2)
```

In words, we (1) take the gapminder data, (2) filter to observations where the country is "Canada", and (3) display the first two observations.


---
# Subsetting rows

We often get *big* datasets, but only want to use a portion of them. We can subset portions of our data using the `filter()` function.

--

Last week we used the `filter()` command to subset data:
```{r}
Canada <- gapminder %>% filter(country == "Canada")
```

We now have the object `Canada` saved in our environment, which contains all observations of the gapminder data from the country Canada.

.footnote[[1] Reminder: `==` is an operator that tests for equality.]

---
# Another Operator: `%in%`

What if I want to subset data from multiple countries at once?! Use the `%in%` operator!

--

We can use `%in%` like `==` but for matching *any element* in the vector on its right<sup>1</sup>. 

```{r}
former_yugoslavia <- c("Bosnia and Herzegovina", "Croatia", 
                       "Montenegro", "Serbia", "Slovenia")
Yugoslavia <- gapminder %>% filter(country %in% former_yugoslavia)
head(Yugoslavia, 4)
```


.footnote[[1] Reminder: The `c()` function is how we make **vectors** in R.]

---
## Finding unique values

Sometimes you want to see the unique combinations of variables that exist in your dataset. You can do this using the function `distinct()`.

--

For example, what if we want to see what unique combinations of "continent" and "year" are in gapminder:

```{r}
gapminder %>% distinct(continent, year) %>% head(6)
```

---
## `distinct()` drops variables!


By default, `distinct()` drops all unused variables. If you don't want to drop the others, use `distinct(.keep_all=TRUE)`:

```{r}
gapminder %>% distinct(continent, year, .keep_all=TRUE) %>% head(6)
```

---
## Keeping or dropping variables

What if we want to subset *variables* (as opposed to observations)? Use the `select()` function!

--

If we want to view the variables "country", "year", and "pop" (in that order), we can do so using the following code: 
```{r}
Yugoslavia %>% select(country, year, pop) %>% head(4)
```

---
## Dropping columns

Alternatively, we can use `select()` to drop variables using a `-` sign: 

```{r}
Yugoslavia %>% select(-continent, -pop, -lifeExp) %>% head(4)
```

Now, we're showing all variables *except* "continent", "pop", and "lifeExp".

---

## Extracting a single column?

Sometimes you want to extract a single column from a data frame as a *vector* (or single value). `pull()` *pulls* a column of a data frame out as a vector.

--

```{r}
gapminder %>% pull(lifeExp) %>% head(4)
```

--

```{r}
gapminder %>% select(lifeExp) %>% head(4)
```

.pull-right[.footnote[Note the difference between these two operations: The second yields only one column but is still a data frame.]]
---

## In-Line `pull()`

`pull()` is particularly useful when you want to use a vector-only command in a `dplyr` chain of functions (say, in an in-line expression).

--

This in-line code...

<p><code>The average life expectancy in Afghanistan from 1952 to 2007 was </code><code  class="r">`</code><code class="r">r gapminder %>% filter(country=="Afghanistan") %>% pull(lifeExp) %>% mean() %>% round(1)`</code><code> years.</code></p>

--

... will produce this output:

The average life expectancy in Afghanistan from 1952 to 2007 was `r gapminder %>% filter(country=="Afghanistan") %>% pull(lifeExp) %>% mean() %>% round(1)` years.


NOTE: `mean()` can only take a *vector* input, not a data frame. So this won't work with `select(lifeExp)` instead of `pull(lifeExp)`.

---
class:inverse

# Check Your Understanding:

With a neighbor or two, write one line of code to answer each of the following questions:

1. Create an object that includes all rows in gapminder from the continents Asia and Oceania

2. Remove the variables "lifeExp" and "gdpPercap" from your subsetted data.

3. Display the distinct combinations of "country" and "continent" from your subsetted data, but do not drop the remaining variables!

---

# My Solution

### 1: Filter Asia and Oceania:
```{r}
Asia_and_Oceania <- gapminder %>% 
  filter(continent %in% c("Asia", "Oceania"))
head(Asia_and_Oceania,4)
```


---

# My Solution

### 2: Drop "lifeExp" and "gdpPercap":

```{r}
Asia_and_Oceania <- Asia_and_Oceania %>% select(-lifeExp,-gdpPercap)
head(Asia_and_Oceania,4)
```


---

# My Solution

### 3: Display distinct "country" and "continent" without dropping:

```{r}
Asia_and_Oceania %>% 
  distinct(country,continent,.keep_all=TRUE) %>%
  head(4)
```

---
class: inverse

# Modifying data

+ `arrange()`
+ `rename()`
+ `mutate()`
+ `recode()`


---
## Sorting data by rows

Sometimes we want to sort data by row, in either ascending (lower to high) or descending (high to low) order. We can do that with `arrange()`.

`arrange` uses ascending order by default. Arrange by descending order using the function `desc`.

--

For example, we can sort Yugoslavia first by year and population:

```{r}
Yugoslavia %>% arrange(year, desc(pop)) %>% head(6)
```


---
## Rename variables

You may receive data with unintuitive variable names. You can change them using `rename()`.


```{r}
Yugoslavia %>% select(country,year,lifeExp) %>%
  rename(Life_Expectancy = lifeExp) %>%
    head(4)
```

(NOTE: I did *not* re-save the object Yugoslavia, so the name change is *not* permanent!)

---
## Column Naming Practices

* *Good* column names are self-describing. Don't use inscrutable abbreviations to save typing, since RStudio can autocomplete.

--

* *Valid* "naked" column names can contain upper or lowercase letters, numbers, periods, and underscores. They must start with a letter or period and not be a special reserved word (e.g. `TRUE`, `if`).

--

* Names are case-sensitive: `Year` and `year` are not the same thing!

--

* You can include spaces if you put backticks around the name.

---
## Column Name with Space Example

```{r}
library(pander)
Yugoslavia %>% filter(country == "Serbia") %>%
    select(year, lifeExp) %>%
    rename(Year = year, `Life Expectancy` = lifeExp) %>% #<<
    head(5) %>%
    pander(style = "rmarkdown", caption = "Serbian life expectancy")
```

---
## Create new columns

You can add new columns to a data frame using `mutate()`. 

--

For example, we could add a new variable that provides the population in millions: 

```{r}
Yugoslavia %>% select(country, year, pop) %>%
    mutate(pop_million = pop / 1000000) %>% #<<
    head(5)
```

Note you can create multiple variables in a single `mutate()` call by separating the expressions with commas.

---
## Recoding variables

We've renamed *variables*, but what about variable *values*?

--

We can use the function `recode()` inside `mutate()`, which allows us to change specific values to others. This is best for categorical data. You can change multiple values at the same time!

```{r}
Yugoslavia %>% 
  mutate(country = recode(country, 
                        `Bosnia and Herzegovina`="B and H", #<<
                        Montenegro="M")) %>%
  distinct(country, .keep_all=TRUE)
```

---
class:inverse

# Check Your Understanding:

Try to answer the following questions on your own, then share your solutions with a neighbor

1. Sort the gapminder data by population in ascending order and print the first 5 rows. What's the country/year with the smallest population?

2. Filter the gapminder data to the countries "United States and "United Kingdom". Then, recode the country values to "US" and "UK", respectively. Print the unique combinations of country and continent.

---

# My Solution

### 1: Sort by population
```{r}
gapminder %>% arrange (pop) %>%  head(5)
```

---

# My Solution

### 2: Display US and UK
```{r}
gapminder %>% 
  filter(country %in% c("United States","United Kingdom")) %>%
  mutate(country = recode(country,
                          "United States" = "US",
                          "United Kingdom"="UK")) %>%
  distinct(country,continent)
```

---
class: inverse

# Summarizing data

1. `summarize()`
3. `group_by()`

---
## Summarizing data

**`summarize()`** takes your column(s) of data and computes something using every row: 

* Count how many rows there are
* Calculate the mean
* Compute the sum
* Obtain a minimum or maximum value

You can use any function inside `summarize()` that aggregates *multiple values* into a *single value* (like `sd()`, `mean()`, or `max()`).

---
## `summarize()` Example

For the year 1982, let's get the number of observations, total population, mean life expectancy, and range of life expectancy for former Yugoslavian countries.

```{r}
Yugoslavia %>% filter(year == 1982) %>%
    summarize(n_obs          = n(),
              total_pop      = sum(pop),
              mean_life_exp  = mean(lifeExp),
              range_life_exp = max(lifeExp) - min(lifeExp))
```

These new variables are calculated using *all of the rows* in `Yugoslavia`

---
## Summarizing data by groups

You may be interested in summarizing data by a categorical variable. For example, what is the combined population of countries in former Yugoslavia by year?

The function `group_by()` helps us do this by changing how functions operate on the data.

--

Functions after `group_by()` are computed *within each group* as defined by variables given, rather than over all rows at once. `group_by()` works best on discrete variables.

Excel analogue: pivot tables

.image-50[![Pivot table](http://www.excel-easy.com/data-analysis/images/pivot-tables/two-dimensional-pivot-table.png)]

---
## `group_by()` Example


```{r}
Yugoslavia %>%
  group_by(year) %>% #<<
  summarize(num_countries     = n_distinct(country),
            total_pop         = sum(pop),
            total_gdp_per_cap = sum(pop*gdpPercap)/total_pop) %>%
  head(5)
```

Because we did `group_by()` with `year` then used `summarize()`, we get *one row per value of `year`*!

Each value of year is its own **group**!

---
class:inverse

# Check Your Understanding:

Try to answer the following questions on your own, then share your solutions with a neighbor.

1. Calculate the mean GDP for Canada, United States, and Mexico between 2000 and 2010. *HINT: Filter the data based on countries and years, then group the data by country, and then summarize.*

2. Plot the mean GDP for each country during the decade 2000-2010 using `ggplot`. Try to make sure the axis labels and limits look nice, and add a title. 

---

# My Solution

### 1: Mean GDP by Country in North America, 2000-2010.
```{r}
meanGDP_2000s <- gapminder %>% 
  filter(country %in% c("Canada","United States","Mexico"), 
         year > 2000 & year <= 2010) %>% 
  group_by(country) %>%
  summarize(meanGDP = mean(gdpPercap))
meanGDP_2000s
```

---

# My Solution

### 2: Plot the data

.smallish[
```{r fig.height=5}
library(ggplot2)
ggplot(meanGDP_2000s,aes(country,meanGDP)) +geom_col() + 
  xlab("Country") + ylab("Mean GDP") + ylim(c(0,45000)) + 
  ggtitle("Average GDP by Country (2000-2010)",subtitle = "North America")
```
]

---
class: inverse
##Joining (Merging) Data

1. `left_join()`
3. `full_join()`

---
## When Do We Need to Join Tables?

In practice, you may need to collect data from different sources. Merging those datasets can be tricky!

--

For example, imagine you would like to study county-level patterns with respect to age and grocery spending. However, you can only find,

* County level age data from the US Census, and 
* County level grocery spending data from the US Department of Agriculture

Solution: Join the datasets!


---
## Joining in Concept

We need to think about the following when we want to merge data frames `A` and `B`:

* Which **rows** are we keeping from each data frame?

  + *Example: One row for each county*

* Which **columns** are we keeping from each data frame?

  + *Example: County name, mean age, mean grocery spending*

* Which variables determine whether rows **match**?

  + *Example: County name*

---
## Join Types: Rows and columns kept

We'll focus on two types of joins:<sup>1</sup>...

* `A %>% left_join(B)`: keep all rows from `A`, matched with `B` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% full_join(B)`: keep all rows from both `A` and `B`, matched wherever possible (`NA` when not), keep columns from both `A` and `B`


.pull-right[.footnote[[1] Other types include `right_join`, `inner_join`, `semi_join`, and `anti_join`, but we won't study those here.]]

---
## Matching Criteria

We say rows should *match* because they have some columns containing the same value. We list these in a `by = ` argument to the join.

--

Matching Behavior:

* `by = c("var1", "var2")`: Match on identical values of `var1`, and `var2` in both `A` and `B`.

--

* `by = c("A_var1" = "B_var1", "A_var2" = "B_var2")`: Match identical values of `A_var1` variable in `A` to `B_var1` variable in `B`, and `A_var2` variable in `A` to `B_var2` variable in `B`.

--

* If you don't include `by`: Match using all variables in `A` and `B` that have identical names.

Note: If there are multiple matches, you'll get *one row for each possible combination*.

---
## `nycflights13` Data

We'll use data in the [`nycflights13` package](https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf). Install and load it:
.smallish[
```{r}
# install.packages("nycflights13") # Uncomment to run
library(nycflights13)
```
]

It includes five data frames, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

Note these are *separate data frames*, each needing to be *loaded separately*:
.smallish[
```{r, eval=FALSE}
data(flights)
data(airlines)
data(airports)
data(planes)
data(weather)
```
]
---
## Join Example #1

The "flights" data doesn't has carrier abbreviations, but not full names. That information is in the "airlines" data. Let's join them together!

--

```{r}
flights %>% left_join(airlines, by = "carrier") %>%
  select(flight,origin,dest,carrier,name) %>%
  head(5)
```

Why use `left_join` and not `full_join`?

---
## Join Example #2

Which airlines had the most flights to Seattle?

--

```{r}
flights %>% left_join(airlines, by = "carrier") %>%
  filter(dest == "SEA") %>%
  group_by(name) %>% 
  summarize(num_flights = n())
```


---
## Join Example #3

The "flights" data doesn't has plane manufacturer information, but "manufacturer" does. Let's join them together!

--


```{r}
flights %>% left_join(planes, by = "tailnum") %>%
  select(flight,origin,dest,tailnum,manufacturer) %>%
  head(5)
```

Why use `left_join` and not `full_join`?

---
## Join Example #4

How many flights from JFK to Seattle were made by each manufacturer?

--

```{r}
flights %>% left_join(planes, by = "tailnum") %>%
  filter(origin == "JFK",dest == "SEA") %>% 
  group_by(manufacturer) %>% 
  summarize(count_flights = n())
```
---
## Join Example #5

Let's plot who manufactures the planes that flew from JFK to Seattle:

--

.smallish[
```{r fig.height=4,fig.width=9}
JFK_Seattle_manufacturers <- flights %>% left_join(planes, by = "tailnum") %>%
  filter(origin == "JFK",dest == "SEA") %>% 
  group_by(manufacturer) %>% summarize(count_manufacturer = n())
ggplot(JFK_Seattle_manufacturers,aes(manufacturer,count_manufacturer))+
  geom_col()+xlab("Manufacturer")+ylab("Count")
```
]

---
## Tinkering Suggestions

Some possible questions to investigate:

* What are the names of the most common destination airports?
* Which airlines fly from NYC to your home city?
*  What is the distribution of departure times for flights leaving NYC over a 24 hour period?
    + Are especially late or early arrivals departures to some regions or for some airlines?

**Warning:** `flights` has `r nrow(flights)` rows, so if you do a sloppy join, you can end up with **many** matches per observation and have the data *explode* in size.

---
class: inverse

# Homework 3

Pick something to look at in the `nycflights13` data and write up a .Rmd file showing your investigation. Upload both the .Rmd file and the .html file to Canvas. 

You must:

1. Use each of the following functions at least once: `mutate()`, `summarize()`, `group_by()`, and `left_join()`. 
2. Include at least one nicely formatted plot (`ggplot2`) and at least one nicely formatted table (`pander`). In plots and tables, use "nice" variable names (try out spaces!) and rounded values (<= 3 digits).
3. Briefly write down your question, observations from your analyses, and a summary of your work in words.


This time, *include all your code in your output document* (`echo=TRUE`), using comments and line breaks separating commands so that it is clear to a peer what you are doing (or trying to do!).

